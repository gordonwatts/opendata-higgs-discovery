{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc22f81-737d-4187-860a-68b11b744fb5",
   "metadata": {},
   "source": [
    "# CMS $H \\rightarrow ZZ \\rightarrow \\ell \\ell \\ell \\ell$ Public Outreach Example\n",
    "\n",
    "CMS has released its higgs discovery dataset as public data. The structure of this is very similar to the ATLAS example, with some important differences:\n",
    "\n",
    "* CMS data is not a flat ROOT tuple, but a CMS Run 1 AOD.\n",
    "\n",
    "Outline\n",
    "\n",
    "1. Use `ServiceX` for general quality and object selection\n",
    "1. Use `coffea` and `awkward` to do multi-object event wide selection and plots\n",
    "1. Produce the plot for running on a single MC file\n",
    "1. Run on all the MC and Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a6ee3a-86cf-4f51-abe1-2254f36cb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_adl_servicex import ServiceXSourceCMSRun1AOD\n",
    "from servicex.servicex import ServiceXDataset\n",
    "from coffea.processor.servicex import Analysis, DataSource, LocalExecutor\n",
    "from func_adl import ObjectStream\n",
    "from hist import Hist\n",
    "\n",
    "import asyncio\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016886c0-a77e-4c98-b687-987703db4e6a",
   "metadata": {},
   "source": [
    "## Defining the base query\n",
    "\n",
    "* We are using the CMS Run 1 AOD file type here\n",
    "* No global event cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bda4e26-5e39-406e-93f1-33046e7c330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ServiceXSourceCMSRun1AOD('cernopendata://dummy')\n",
    "ds.return_qastle = True  # Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82448bc0-e02e-419a-93ab-d4ae42cf9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting Clean Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6aa0dd6-8e60-417b-b319-d379942f2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "leptons_source = (\n",
    "    ds\n",
    "    .Select(lambda e: {\n",
    "        \"m\": e.Muons(\"muons\"),\n",
    "        \"e\": e.GsfElectrons(\"gsfElectrons\"), \n",
    "        \"p\": e.Vertex(\"offlinePrimaryVertices\")[0].position()\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad79f719-0a22-4d46-b302-d1b9194e2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_leptons = (\n",
    "     leptons_source\n",
    "     .Select(lambda i: {\n",
    "          \"m\": i.m\n",
    "               .Where(lambda m: m.isPFMuon()\n",
    "                         and m.isPFIsolationValid()\n",
    "                         and isNonnull(m.globalTrack())\n",
    "                         and abs(sqrt((m.globalTrack().dxy(i.p) * m.globalTrack().dxy(i.p))\n",
    "                                   + (m.globalTrack().dz(i.p) * m.globalTrack().dz(i.p)))\n",
    "                              / sqrt((m.globalTrack().d0Error() * m.globalTrack().d0Error())\n",
    "                                        + (m.globalTrack().dzError() * m.globalTrack().dzError()))) < 4.0\n",
    "                         and abs((m.globalTrack()).dxy(i.p)) < 0.5\n",
    "                         and abs((m.globalTrack()).dz(i.p)) < 1.\n",
    "                         and ((m.pfIsolationR04()).sumChargedHadronPt\n",
    "                              + (m.pfIsolationR04()).sumNeutralHadronEt\n",
    "                              + (m.pfIsolationR04()).sumPhotonEt) / m.pt() < 0.4\n",
    "                         and m.pt() > 5.\n",
    "                         and abs(m.eta()) < 2.4\n",
    "               ),\n",
    "          \"e\": i.e\n",
    "               .Where(lambda e: e.passingPflowPreselection()\n",
    "                         and e.pt() > 7.\n",
    "                         and abs(e.superCluster().eta()) < 2.5\n",
    "                         and e.gsfTrack().trackerExpectedHitsInner().numberOfHits() <= 1\n",
    "                         and abs(sqrt((e.gsfTrack().dxy(i.p) * e.gsfTrack().dxy(i.p))\n",
    "                                   + (e.gsfTrack().dz(i.p) * e.gsfTrack().dz(i.p)))\n",
    "                              / sqrt((e.gsfTrack().d0Error() * e.gsfTrack().d0Error())\n",
    "                                        + (e.gsfTrack().dzError() * e.gsfTrack().dzError()))) < 4.\n",
    "                         and abs(e.gsfTrack().dxy(i.p)) < 0.5 and abs(e.gsfTrack().dz(i.p)) < 1.\n",
    "                         and (e.isEB() or e.isEE())\n",
    "                         and (e.pfIsolationVariables().chargedHadronIso\n",
    "                              + e.pfIsolationVariables().neutralHadronIso\n",
    "                              + e.pfIsolationVariables().photonIso) / e.pt() < 0.4\n",
    "                         )\n",
    "     })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53cfbb-602f-400e-9144-5bef2572b5e1",
   "metadata": {},
   "source": [
    "And pull out the columns we need for selection in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a88be73-be15-440a-bfc5-d4cc3a80ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms_selection = (\n",
    "    data_leptons\n",
    "    .Select(lambda i: (\n",
    "        i.m.Select(lambda m: m.p()),\n",
    "        i.m.Select(lambda m: m.pt()),\n",
    "        i.m.Select(lambda m: m.px()),\n",
    "        i.m.Select(lambda m: m.py()),\n",
    "        i.m.Select(lambda m: m.pz()),\n",
    "        i.m.Select(lambda m: m.charge()),\n",
    "        i.e.Select(lambda m: m.p()),\n",
    "        i.e.Select(lambda m: m.pt()),\n",
    "        i.e.Select(lambda m: m.px()),\n",
    "        i.e.Select(lambda m: m.py()),\n",
    "        i.e.Select(lambda m: m.pz()),\n",
    "        i.e.Select(lambda m: m.charge()),\n",
    "    ))\n",
    "    .AsROOTTTree('junk.root', 'analysis', columns = [\n",
    "        'mu_p', 'mu_pt', 'mu_px', 'mu_py', 'mu_pz', 'mu_charge',\n",
    "        'el_p', 'el_pt', 'el_px', 'el_py', 'el_pz', 'el_charge',\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df477b-c580-4f87-93a7-de7d7083f378",
   "metadata": {},
   "source": [
    "## Performing the Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c21f0b21-d812-4286-aacc-fd05a65ca3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMS_Higgs_4L(Analysis):\n",
    "    '''Run the 4 Lepton analysis on CMS open data Run 1 AOD's\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def process(events):\n",
    "        from collections import defaultdict\n",
    "        import numpy as np\n",
    "\n",
    "        import awkward as ak\n",
    "\n",
    "        sumw = defaultdict(float)\n",
    "        mass_hist = (Hist.new\n",
    "                     .Reg(60, 60, 180, name='mass', label='$m_{4\\ell}$ [GeV]')\n",
    "                     .StrCat([], name='dataset', label='Cut Type', growth=True)\n",
    "                     .StrCat([], name='channel', label='Channel', growth=True)\n",
    "                     .Int64()\n",
    "                    )\n",
    "\n",
    "        dataset = events.metadata['dataset']\n",
    "#         electrons = events.electrons\n",
    "#         muons = events.muons\n",
    "        \n",
    "#         weight =  ak.Array(np.ones(len(events.scaleFactor))) if events.metadata['is_data'] \\\n",
    "#             else events.scaleFactor*events.mcWeight\n",
    "\n",
    "#         # We didn't have the 4-vector in `ServiceX`, so we couldn't do the final good-object cut.\n",
    "        \n",
    "#         # Good electon selection\n",
    "#         electrons_mask = (abs(electrons.z0*np.sin(electrons.theta)) < 0.5)\n",
    "#         electrons_good = electrons[electrons_mask]\n",
    "\n",
    "#         # Good muon selection\n",
    "#         muons_mask = (abs(muons.z0*np.sin(muons.theta)) < 0.5)\n",
    "#         muons_good = muons[muons_mask]\n",
    "\n",
    "#         # Next are event level cuts\n",
    "        \n",
    "#         # In order to cut in sorted lepton pt, we have to rebuild a lepton array here\n",
    "#         leptons_good = ak.concatenate((electrons_good, muons_good), axis=1)\n",
    "#         leptons_good_index = ak.argsort(leptons_good.pt, ascending=False)\n",
    "#         leptons_good_sorted = leptons_good[leptons_good_index]\n",
    "\n",
    "#         # Event level cuts now that we know the good leptons\n",
    "#         # - We need to look at 4 good lepton events only\n",
    "#         # - We need same flavor, so check for even numbers of each flavor\n",
    "#         # - all charges must be balenced\n",
    "#         event_mask = (\n",
    "#             (ak.num(leptons_good_sorted) == 4)\n",
    "#             & ((ak.num(electrons_good) == 0) | (ak.num(electrons_good) == 2) | (ak.num(electrons_good) == 4))\n",
    "#             & ((ak.num(muons_good) == 0) | (ak.num(muons_good) == 2) | (ak.num(muons_good) == 4))\n",
    "#             & (ak.sum(electrons_good.charge, axis=1) == 0)\n",
    "#             & (ak.sum(muons_good.charge, axis=1) == 0)\n",
    "#         )\n",
    "        \n",
    "#         # Next, we need to cut on the pT for the leading, sub-leading, and sub-sub-leading lepton\n",
    "#         leptons_good_preselection = leptons_good[event_mask]\n",
    "#         event_good_lepton_mask = (\n",
    "#             (leptons_good_preselection[:,0].pt > 25000.0)\n",
    "#             & (leptons_good_preselection[:,1].pt > 15000.0)\n",
    "#             & (leptons_good_preselection[:,2].pt > 10000.0)\n",
    "#         )\n",
    "\n",
    "#         # Now, we need to rebuild the good muon and electron lists with those selections\n",
    "#         muons_analysis = muons_good[event_mask][event_good_lepton_mask]\n",
    "#         electrons_analysis = electrons_good[event_mask][event_good_lepton_mask]\n",
    "\n",
    "#         # Lets do eemumu events - as there are no permutations there.abs\n",
    "#         # At this point if there are two muons, there must be two electrons\n",
    "#         eemumu_mask = (ak.num(muons_analysis) == 2)\n",
    "#         muon_eemumu = muons_analysis[eemumu_mask]\n",
    "#         electrons_eemumu = electrons_analysis[eemumu_mask]\n",
    "#         z1_eemumu = muon_eemumu[:,0] + muon_eemumu[:,1]\n",
    "#         z2_eemumu = electrons_eemumu[:,0] + electrons_eemumu[:,1]\n",
    "#         h_eemumu = z1_eemumu + z2_eemumu\n",
    "\n",
    "#         sumw[dataset] += len(h_eemumu)\n",
    "#         mass_hist.fill(\n",
    "#             channel=r'$ee\\mu\\mu$',\n",
    "#             mass=h_eemumu.mass/1000.0,\n",
    "#             dataset=dataset,\n",
    "#             weight=weight[eemumu_mask]\n",
    "#         )\n",
    "\n",
    "#         # Next, eeee. For this we have to build permutations and select the best one\n",
    "#         def four_leptons_one_flavor(same_flavor_leptons, event_weights, channel: str):\n",
    "#             fl_positive = same_flavor_leptons[same_flavor_leptons.charge > 0]\n",
    "#             fl_negative = same_flavor_leptons[same_flavor_leptons.charge < 0]\n",
    "#             fl_pairs = ak.cartesian((fl_positive, fl_negative))\n",
    "#             # fl_pairs_args = ak.argcartesian((fl_positive, fl_negative))\n",
    "#             zs = fl_pairs[\"0\"] + fl_pairs[\"1\"]\n",
    "\n",
    "#             delta = abs((91.18*1000.0) - zs.mass[:])\n",
    "#             closest_masses = np.min(delta, axis=-1)\n",
    "#             the_closest = (delta == closest_masses)\n",
    "#             the_furthest = the_closest[:,::-1]\n",
    "\n",
    "#             h_eeee = zs[the_closest] + zs[the_furthest]\n",
    "#             sumw[dataset] += len(h_eeee)\n",
    "#             mass_hist.fill(\n",
    "#                 channel=channel,\n",
    "#                 mass=ak.flatten(h_eeee.mass/1000.0),\n",
    "#                 dataset=dataset,\n",
    "#                 weight=event_weights,\n",
    "#             )\n",
    "\n",
    "#         four_leptons_one_flavor(electrons_analysis[(ak.num(electrons_analysis) == 4)],\n",
    "#                                 weight[(ak.num(electrons_analysis) == 4)],\n",
    "#                                 '$eeee$')\n",
    "#         four_leptons_one_flavor(muons_analysis[(ak.num(muons_analysis) == 4)],\n",
    "#                                 weight[(ak.num(muons_analysis) == 4)],\n",
    "#                                 '$\\\\mu\\\\mu\\\\mu\\\\mu$')\n",
    "        \n",
    "        return {\n",
    "            \"sumw\": sumw,\n",
    "            \"mass\": mass_hist,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40403dc4-c298-4c04-a9db-e0ce5425177d",
   "metadata": {},
   "source": [
    "# Run on a MC File\n",
    "\n",
    "Again, we will run on a CMS Higgs MC sample to demonstrate this all works before unleashing it on all the data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2793ea0-beb9-4e4f-9875-3cda954bea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(name: str, query: ObjectStream):\n",
    "    '''Create a ServiceX Datasource for a particular ATLAS Open data file\n",
    "    '''\n",
    "    from utils import cms_files\n",
    "    datasets = [ServiceXDataset(cms_files[name]['files'], backend_type='cms_run1_aod', image='sslhep/servicex_func_adl_uproot_transformer:pr_fix_awk_bug')]\n",
    "    return DataSource(query=query, metadata={'dataset': name}, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e54cbf8c-76a9-40b0-a1c5-e8884767b657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SMHiggsToZZTo4L_M-125_7TeV'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import cms_files\n",
    "all_datasets = list(cms_files.keys())\n",
    "', '.join(all_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226cc35b-6829-47f5-8bbc-6b9397bbcc08",
   "metadata": {},
   "source": [
    "The routine that will run on multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa7eeae3-167d-488a-89e6-d77d0eab770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_analysis(names: List[str]):\n",
    "    'Generate base plot for a multiple datafiles'\n",
    "\n",
    "    executor = LocalExecutor(datatype='root')\n",
    "    datasources = [make_ds(ds_name, cms_selection) for ds_name in names]\n",
    "\n",
    "    # Create the analysis and we can run from there.\n",
    "    analysis = CMS_Higgs_4L()\n",
    "\n",
    "    async def run_updates_stream(accumulator_stream, name):\n",
    "        '''Run to get the last item in the stream, with a useful error message'''\n",
    "        coffea_info = None\n",
    "        try:\n",
    "            async for coffea_info in accumulator_stream:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failure while processing {name}') from e\n",
    "        return coffea_info\n",
    "\n",
    "    # Run on all items and wait till they are done!\n",
    "    all_plots = await asyncio.gather(*[run_updates_stream(executor.execute(analysis, source), source.metadata['dataset']) for source in datasources])\n",
    "    \n",
    "    all_plots_mass = [p['mass'] for p in all_plots]\n",
    "    mass = all_plots_mass[0]\n",
    "    for p in all_plots_mass[1:]:\n",
    "        mass += p\n",
    "\n",
    "    return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0acb4a-8a56-4d30-ad28-e7966ed22b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113be5c4f5ec45e4a1d51ebf58df84a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cernopendata://1507:   0%|                                                                       | 0/900000000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe3dac9478f429999d488b203623388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "        Downloaded:   0%|                                                                        | 0/900000000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mc_mass_plot = await run_analysis(['SMHiggsToZZTo4L_M-125_7TeV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a611975-3da6-480d-8104-3ec57af5c5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
