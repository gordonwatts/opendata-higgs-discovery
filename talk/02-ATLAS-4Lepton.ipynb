{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2dcd48-744d-41e0-b19f-eea73324afa6",
   "metadata": {},
   "source": [
    "# ATLAS $H \\rightarrow ZZ \\rightarrow \\ell \\ell \\ell \\ell$ Public Outreach Example\n",
    "\n",
    "ATLAS has released its higgs discovery dataset as public data:\n",
    "\n",
    "* Use `ServiceX` to stream the 4 lepton data\n",
    "* Use `coffea` and `awkward` to produce the final $m_{4\\ell}$ plots.\n",
    "* This is **only** aboput 0.5 GB worth of data!\n",
    "\n",
    "Outline\n",
    "\n",
    "1. Use `ServiceX` for general quality and object selection\n",
    "1. Use `coffea` and `awkward` to do multi-object event wide selection and plots\n",
    "1. Produce the plot for running on a single MC file\n",
    "1. Run on all the MC and Data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f305ecf-7316-47b8-8467-8a59f78d4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_adl_servicex import ServiceXSourceUpROOT\n",
    "from servicex.servicex import ServiceXDataset\n",
    "from coffea.processor.servicex import Analysis, DataSource, LocalExecutor\n",
    "from func_adl import ObjectStream\n",
    "from hist import Hist\n",
    "\n",
    "import asyncio\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675511ff-0a5a-4184-a7b9-65ff0e640972",
   "metadata": {},
   "source": [
    "## Selecting events and clean objects\n",
    "\n",
    "The ATLAS analysis ...\n",
    "\n",
    "First we create the representative data source, and apply the initial trigger requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49712cf5-b907-4f2f-acf3-39443b44a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ServiceXSourceUpROOT('cernopendata://dummy',  \"mimi\", backend='open_uproot')\n",
    "ds.return_qastle = True  # Magic\n",
    "\n",
    "good_events = (ds\n",
    "               .Where(lambda e: e.trigE or e.trigM)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ccea5-c0b6-4070-853a-59e804f0ea40",
   "metadata": {},
   "source": [
    "Next, basic lepton selection:\n",
    "\n",
    "* Turn the columnar representation into object so we can make cuts\n",
    "* Apply the common base cuts for electrons and muons\n",
    "* We also need the event weights, which are baked into the ntuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ba27f-c3c4-461b-831d-4324f71ec53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_leptons = (good_events\n",
    "                .Select(lambda e: (\n",
    "                    Zip({\n",
    "                        'lep_pt': e.lep_pt,\n",
    "                        'lep_eta': e.lep_eta,\n",
    "                        'lep_phi': e.lep_phi,\n",
    "                        'lep_energy': e.lep_E,\n",
    "                        'lep_charge': e.lep_charge,\n",
    "                        'lep_ptcone30': e.lep_ptcone30,\n",
    "                        'lep_etcone20': e.lep_etcone20,\n",
    "                        'lep_typeid': e.lep_type,\n",
    "                        'lep_trackd0pvunbiased': e.lep_trackd0pvunbiased,\n",
    "                        'lep_tracksigd0pvunbiased': e.lep_tracksigd0pvunbiased,\n",
    "                        'lep_z0': e.lep_z0,\n",
    "                    }),\n",
    "                    e.mcWeight,\n",
    "                    e.scaleFactor_ELE*e.scaleFactor_MUON*e.scaleFactor_LepTRIGGER*e.scaleFactor_PILEUP,\n",
    "                ))\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b300cc-e5ca-4011-9b90-088f89d1e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_leptons = (all_leptons\n",
    "                .Select(lambda e: {\n",
    "                    'ele': e[0]\n",
    "                           .Where(lambda lep: lep.lep_typeid == 11)\n",
    "                           .Where(lambda lep: (lep.lep_pt > 7000)\n",
    "                                              and (abs(lep.lep_eta) < 2.47)\n",
    "                                              and (lep.lep_etcone20/lep.lep_pt < 0.3)\n",
    "                                              and (lep.lep_ptcone30/lep.lep_pt < 0.3)\n",
    "                                              and (abs(lep.lep_trackd0pvunbiased) / lep.lep_tracksigd0pvunbiased < 5)\n",
    "                                 ),\n",
    "                    'mu': e[0]\n",
    "                           .Where(lambda lep: lep.lep_typeid == 13)\n",
    "                           .Where(lambda lep: (lep.lep_pt > 5000)\n",
    "                                              and (abs(lep.lep_eta) < 2.5)\n",
    "                                              and (lep.lep_etcone20/lep.lep_pt < 0.3)\n",
    "                                              and (lep.lep_ptcone30/lep.lep_pt < 0.3)\n",
    "                                              and (abs(lep.lep_trackd0pvunbiased) / lep.lep_tracksigd0pvunbiased < 3)\n",
    "                                 ),\n",
    "                    'mcWeight': e[1],\n",
    "                    'scaleFactor': e[2],\n",
    "                })\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058430d-193c-4038-970f-178578897249",
   "metadata": {},
   "source": [
    "And finally, we have to turn this into a form that coffea can currently understand.\n",
    "\n",
    "* We only need to feed columns we will use downstream out of `ServiceX`, reducing the dataload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aeefe6-e286-4276-b10c-13954833d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_selection = (good_leptons\n",
    "                   .Select(lambda e: {\n",
    "                       'electrons_pt': e.ele.lep_pt,\n",
    "                       'electrons_eta': e.ele.lep_eta,\n",
    "                       'electrons_phi': e.ele.lep_phi,\n",
    "                       'electrons_energy': e.ele.lep_energy,\n",
    "                       'electrons_charge': e.ele.lep_charge,\n",
    "                       'electrons_z0': e.ele.lep_z0,\n",
    "                       'muons_pt': e.mu.lep_pt,\n",
    "                       'muons_eta': e.mu.lep_eta,\n",
    "                       'muons_phi': e.mu.lep_phi,\n",
    "                       'muons_energy': e.mu.lep_energy,\n",
    "                       'muons_charge': e.mu.lep_charge,\n",
    "                       'muons_z0': e.mu.lep_z0,\n",
    "                       'mcWeight': e.mcWeight,\n",
    "                       'scaleFactor': e.scaleFactor,\n",
    "                   })\n",
    "                   .AsParquetFiles('junk.parquet')\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156d6bf4-b63c-440c-8b0d-a22f62b5a5f7",
   "metadata": {},
   "source": [
    "## Performing the analysis\n",
    "\n",
    "The data from `ServiceX` is now analyzed by `awkward` and `coffea`.\n",
    "\n",
    "* `coffea` automatically builds _event_ layout for electorns and muons, queuing off the prefix in the names from `ServiceX`\n",
    "* `coffea` recognizes that $p_T$, $\\eta$, $\\phi$, and $E$ are availible, and builds a 4-vector that has a `theta` property.\n",
    "* `awkward` properly translates the `np.sin` to work on an `awkward` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3023aab-7d60-4525-b321-7446b9719759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATLAS_Higgs_4L(Analysis):\n",
    "    '''Run the 4 Lepton analysis on ATLAS educational ntuples\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def process(events):\n",
    "        from collections import defaultdict\n",
    "        import numpy as np\n",
    "\n",
    "        import awkward as ak\n",
    "\n",
    "        sumw = defaultdict(float)\n",
    "        mass_hist = (Hist.new\n",
    "                     .Reg(60, 60, 180, name='mass', label='$m_{4\\ell}$ [GeV]')\n",
    "                     .StrCat([], name='dataset', label='Cut Type', growth=True)\n",
    "                     .StrCat([], name='channel', label='Channel', growth=True)\n",
    "                     .Int64()\n",
    "                    )\n",
    "\n",
    "        dataset = events.metadata['dataset']\n",
    "        electrons = events.electrons\n",
    "        muons = events.muons\n",
    "        \n",
    "        weight =  ak.Array(np.ones(len(events.scaleFactor))) if events.metadata['is_data'] \\\n",
    "            else events.scaleFactor*events.mcWeight\n",
    "\n",
    "        # We didn't have the 4-vector in `ServiceX`, so we couldn't do the final good-object cut.\n",
    "        # Good electon selection\n",
    "        electrons_mask = (abs(electrons.z0*np.sin(electrons.theta)) < 0.5)\n",
    "        electrons_good = electrons[electrons_mask]\n",
    "\n",
    "        # Good muon selection\n",
    "        muons_mask = (abs(muons.z0*np.sin(muons.theta)) < 0.5)\n",
    "        muons_good = muons[muons_mask]\n",
    "\n",
    "        # Next are event level cuts\n",
    "        \n",
    "        # In order to cut in sorted lepton pt, we have to rebuild a lepton array here\n",
    "        leptons_good = ak.concatenate((electrons_good, muons_good), axis=1)\n",
    "        leptons_good_index = ak.argsort(leptons_good.pt, ascending=False)\n",
    "        leptons_good_sorted = leptons_good[leptons_good_index]\n",
    "\n",
    "        # Event level cuts now that we know the good leptons\n",
    "        # - We need to look at 4 good lepton events only\n",
    "        # - We need same flavor, so check for even numbers of each flavor\n",
    "        # - all charges must be balenced\n",
    "        event_mask = (\n",
    "            (ak.num(leptons_good_sorted) == 4)\n",
    "            & ((ak.num(electrons_good) == 0) | (ak.num(electrons_good) == 2) | (ak.num(electrons_good) == 4))\n",
    "            & ((ak.num(muons_good) == 0) | (ak.num(muons_good) == 2) | (ak.num(muons_good) == 4))\n",
    "            & (ak.sum(electrons_good.charge, axis=1) == 0)\n",
    "            & (ak.sum(muons_good.charge, axis=1) == 0)\n",
    "        )\n",
    "        \n",
    "        # Next, we need to cut on the pT for the leading, sub-leading, and sub-sub-leading lepton\n",
    "        leptons_good_preselection = leptons_good[event_mask]\n",
    "        event_good_lepton_mask = (\n",
    "            (leptons_good_preselection[:,0].pt > 25000.0)\n",
    "            & (leptons_good_preselection[:,1].pt > 15000.0)\n",
    "            & (leptons_good_preselection[:,2].pt > 10000.0)\n",
    "        )\n",
    "\n",
    "        # Now, we need to rebuild the good muon and electron lists with those selections\n",
    "        muons_analysis = muons_good[event_mask][event_good_lepton_mask]\n",
    "        electrons_analysis = electrons_good[event_mask][event_good_lepton_mask]\n",
    "\n",
    "        # Lets do eemumu events - as there are no permutations there.abs\n",
    "        # At this point if there are two muons, there must be two electrons\n",
    "        eemumu_mask = (ak.num(muons_analysis) == 2)\n",
    "        muon_eemumu = muons_analysis[eemumu_mask]\n",
    "        electrons_eemumu = electrons_analysis[eemumu_mask]\n",
    "        z1_eemumu = muon_eemumu[:,0] + muon_eemumu[:,1]\n",
    "        z2_eemumu = electrons_eemumu[:,0] + electrons_eemumu[:,1]\n",
    "        h_eemumu = z1_eemumu + z2_eemumu\n",
    "\n",
    "        sumw[dataset] += len(h_eemumu)\n",
    "        mass_hist.fill(\n",
    "            channel=r'$ee\\mu\\mu$',\n",
    "            mass=h_eemumu.mass/1000.0,\n",
    "            dataset=dataset,\n",
    "#             weight=weight[eemumu_mask]\n",
    "        )\n",
    "\n",
    "        # Next, eeee. For this we have to build permutations and select the best one\n",
    "        def four_leptons_one_flavor(same_flavor_leptons, event_weights, channel: str):\n",
    "            fl_positive = same_flavor_leptons[same_flavor_leptons.charge > 0]\n",
    "            fl_negative = same_flavor_leptons[same_flavor_leptons.charge < 0]\n",
    "            fl_pairs = ak.cartesian((fl_positive, fl_negative))\n",
    "            zs = fl_pairs[\"0\"] + fl_pairs[\"1\"]\n",
    "\n",
    "            delta = abs((91.18*1000.0) - zs.mass[:])\n",
    "            closest_masses = np.min(delta, axis=-1)\n",
    "            the_closest = (delta == closest_masses)\n",
    "            the_furthest = the_closest[:,::-1]\n",
    "\n",
    "            h_eeee = zs[the_closest] + zs[the_furthest]\n",
    "            sumw[dataset] += len(h_eeee)\n",
    "            mass_hist.fill(\n",
    "                channel=channel,\n",
    "                mass=ak.flatten(h_eeee.mass/1000.0),\n",
    "                dataset=dataset,\n",
    "#                 weight=event_weights,\n",
    "            )\n",
    "\n",
    "        four_leptons_one_flavor(electrons_analysis[(ak.num(electrons_analysis) == 4)],\n",
    "                                weight[(ak.num(electrons_analysis) == 4)],\n",
    "                                '$eeee$')\n",
    "        four_leptons_one_flavor(muons_analysis[(ak.num(muons_analysis) == 4)],\n",
    "                                weight[(ak.num(muons_analysis) == 4)],\n",
    "                                '$\\\\mu\\\\mu\\\\mu\\\\mu$')\n",
    "        \n",
    "        return {\n",
    "            \"sumw\": sumw,\n",
    "            \"mass\": mass_hist,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5e0df-6be0-487e-8354-fa17d143159a",
   "metadata": {},
   "source": [
    "## Run on a MC file\n",
    "\n",
    "Define a convience function to load MC files - there are a lot of them.\n",
    "\n",
    "* Note the `is_data` metadata - which was used above in an if statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbae50e-f76a-41e5-9ec3-9180a84e079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(name: str, query: ObjectStream):\n",
    "    '''Create a ServiceX Datasource for a particular ATLAS Open data file\n",
    "    '''\n",
    "    from utils import files\n",
    "    is_data = name == 'data'\n",
    "    datasets = [ServiceXDataset(files[name]['files'], backend_type='open_uproot', image='sslhep/servicex_func_adl_uproot_transformer:pr_fix_awk_bug')]\n",
    "    return DataSource(query=query, metadata={'dataset': name, 'is_data': is_data}, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08750e8f-0edc-4682-8eb3-10eb326f493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import files\n",
    "all_datasets = list(files.keys())\n",
    "', '.join(all_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367db9d-7e3f-4aa0-a05f-1e50ef1d2f23",
   "metadata": {},
   "source": [
    "And an easy routine that will run a single file\n",
    "\n",
    "* Async so we can run multiple queires at once\n",
    "* Contains a lot of boiler plate\n",
    "* Runs on multiple datasets at once (which we will need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c1b42-aeac-4918-b043-c07f7b5d4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_analysis(names: List[str]):\n",
    "    'Generate base plot for a multiple datafiles'\n",
    "\n",
    "    executor = LocalExecutor(datatype='parquet')\n",
    "    datasources = [make_ds(ds_name, atlas_selection) for ds_name in names]\n",
    "\n",
    "    # Create the analysis and we can run from there.\n",
    "    analysis = ATLAS_Higgs_4L()\n",
    "\n",
    "    async def run_updates_stream(accumulator_stream, name):\n",
    "        '''Run to get the last item in the stream, with a useful error message'''\n",
    "        coffea_info = None\n",
    "        try:\n",
    "            async for coffea_info in accumulator_stream:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failure while processing {name}') from e\n",
    "        return coffea_info\n",
    "\n",
    "    # Run on all items and wait till they are done!\n",
    "    all_plots = await asyncio.gather(*[run_updates_stream(executor.execute(analysis, source), source.metadata['dataset']) for source in datasources])\n",
    "    \n",
    "    all_plots_mass = [p['mass'] for p in all_plots]\n",
    "    mass = all_plots_mass[0]\n",
    "    for p in all_plots_mass[1:]:\n",
    "        mass += p\n",
    "\n",
    "    return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc9930-b841-4566-b67c-a68637e14378",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mass_plot = await run_analysis(['ggH125_ZZ4lep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058c49c-3d00-46b0-8b00-b17e5218fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = mc_mass_plot.project('mass','channel').plot(stack=True)\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ed9d1-c71a-47f2-bdaf-60e2929f703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mass_plot.project('mass').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b153bdd-90d9-486f-9161-470d0808d0b5",
   "metadata": {},
   "source": [
    "## Running on all MC and Data Files\n",
    "\n",
    "Here we will repeat the above, but unleash it on all our datasets. These will all be put into a single histogram, with the `dataset` bin marking what sample they are from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b700954-e964-4dbc-bb21-d937e18f40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_plot = await run_analysis(all_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d930ff-e8fd-4383-8842-5c7e4e4f1107",
   "metadata": {},
   "source": [
    "Lets plot everything - not that this is interesting from a physics point of view, but it does make sure everything was added to the histogram in the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8692d9-2607-45ad-a058-fd63e968e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = mass_plot.project('mass', 'dataset').plot(stack=True)\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626176b2-b62d-4110-9026-ee30103dd869",
   "metadata": {},
   "source": [
    "First, lets look at the components. We'd like signal, data, and the sum of everything else (MC prediction).\n",
    "\n",
    "Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee8fbc-7661-402d-8c2d-b38e005efa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_plot[:, 'data', :].project('mass').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615370c-a26e-4175-b6fa-5daf34bc54e3",
   "metadata": {},
   "source": [
    "Signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc58bdd-0141-45db-9d60-39678ae8c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_ds = list(d for d in all_datasets if 'H125' in d)\n",
    "\n",
    "artists = mass_plot[:,signal_ds,:].project('mass', 'dataset').plot(stack=True)\n",
    "\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f319de-1927-4879-922d-f0cffdb5911f",
   "metadata": {},
   "source": [
    "Sum of the backgrounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba83d35-b5e7-49f5-8a96-d37e7f024d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_ds = list(str(i) for i in (set(list(mass_plot.axes[1])) - set(signal_ds) - set(['data'])))\n",
    "mc_ds.sort()\n",
    "\n",
    "artists = mass_plot[:,mc_ds,:].project('mass', 'dataset').plot(stack=True)\n",
    "\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780e1f1-f6cc-4dc4-b4a2-03bbf7d47452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
