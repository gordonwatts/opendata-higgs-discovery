{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8217b3fb-69e1-4d49-93fd-61ce8ba34023",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Lets load our environment first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6f9fc-fc3f-4894-90bb-b8b513818232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_adl_servicex import ServiceXSourceUpROOT, ServiceXSourceCMSRun1AOD\n",
    "from hist import Hist\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f8d25-7d7c-4b5e-83c7-db2a95fd9e34",
   "metadata": {},
   "source": [
    "## Flat ROOT Files\n",
    "\n",
    "ATLAS has distributed it's open data as flat ROOT files.\n",
    "\n",
    "* On CERNOpenData they are a single zip file\n",
    "* But they have been distributed as files availible via EOS from CERN Open Data's EOS instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc9e5e-eae9-444e-b794-71cf53bef982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggH125_ZZ4lep = 'root://eospublic.cern.ch//eos/opendata/atlas/OurestartreachDatasets/2020-01-22/4lep/MC/mc_345060.ggH125_ZZ4lep.4lep.root'\n",
    "ggH125_ZZ4lep = 'https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/MC/mc_345060.ggH125_ZZ4lep.4lep.root'\n",
    "ggH125_ZZ4lep_source = ServiceXSourceUpROOT([ggH125_ZZ4lep], 'mini', backend='open_uproot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032e4ea-6623-4da3-9460-73143ddf6dbd",
   "metadata": {},
   "source": [
    "* We use the `root://` address instead of `http://` due to efficiency and caching.\n",
    "* `mini` is the tree name in the file\n",
    "* `backend` basically describes the type of file - this is a flat root file that can be opened by the `uproot` python package.\n",
    "\n",
    "Now that we have a reference to the datasource, lets pick out a single column and bring its contents back to our local instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8fab5d-7219-4e11-be99-766ffaf23d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from servicex import ignore_cache\n",
    "\n",
    "with ignore_cache():\n",
    "    r = (ggH125_ZZ4lep_source\n",
    "         .Select(lambda e: {'lep_pt': e['lep_pt']})\n",
    "         .AsAwkwardArray()\n",
    "         .value()\n",
    "        )\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90e75b-500c-4d2d-a11c-a06d43636c56",
   "metadata": {},
   "source": [
    "This is a standard awkward array - and it's shape is simply a series of lepton $p_T$'s for each of the 164716 events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a1802-422d-4f27-abaa-3fddfbe144eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4b71f-641a-45ea-818e-9501f21c9bd3",
   "metadata": {},
   "source": [
    "Lets plot this. We'll use the `Hist` library, which is a nice wrapper around the `boost_histogram` library:\n",
    "* Note we have a single axis, which is the muon's $p_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a21fd7-7fcf-42e3-8580-8a2feece3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (Hist.new\n",
    "     .Reg(50, 0, 200, name='mu_pt', label='Muon $p_T$ [GeV]')\n",
    "     .Int64()\n",
    "     )\n",
    "h.fill(ak.flatten(r['lep_pt'])/1000.0)\n",
    "_ = h.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae834cf-be13-4df3-9aaa-a93a6952bf0a",
   "metadata": {},
   "source": [
    "Lets get back a $p_T$ and an $\\eta$ for the leptons now. This requires two things coming back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fc566-e2d8-47c7-8624-9b88699ba1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (ggH125_ZZ4lep_source\n",
    "     .Select(lambda e: {'lep_pt': e['lep_pt'], 'lep_eta': e['lep_eta']})\n",
    "     .AsAwkwardArray()\n",
    "     .value()\n",
    "    )\n",
    "r.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23950ec-2a20-40f1-a544-e1ec2a26bfca",
   "metadata": {},
   "source": [
    "Note that it is columnar data:\n",
    "\n",
    "* Each event contains two arrays\n",
    "* The arrays are lepton pt and eta - not a tuple of lepton ($p_T$, $\\eta$).\n",
    "\n",
    "What if we want to cut on the eta? How do we relate these two columns? We use the zip function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8b1e1-28ce-4c28-a1af-61e27d90a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cut = (ggH125_ZZ4lep_source\n",
    "         .Select(lambda e: Zip({'pt': e['lep_pt'], 'eta': e['lep_eta']}))\n",
    "         .Select(lambda leps: leps.Where(lambda l: abs(l.eta) < 1.0))\n",
    "         .AsAwkwardArray()\n",
    "         .value()\n",
    "        )\n",
    "r.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac1f1b-5809-4c36-b304-2b9698842f7a",
   "metadata": {},
   "source": [
    "Interesting - same number of events - but we cut? Lets look at a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648552b-6b86-4fd2-b47e-1868c64f254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (Hist.new\n",
    "     .Reg(50, 0, 200, name='mu_pt', label='Muon Track $p_T$ [GeV]')\n",
    "     .StrCat([], name='cut', label='Cut Type', growth=True)\n",
    "     .Int64()\n",
    "     )\n",
    "h.fill(mu_pt=ak.flatten(r['lep_pt'])/1000.0, cut='All')\n",
    "h.fill(mu_pt=ak.flatten(r_cut['pt'])/1000.0, cut='eta')\n",
    "artists = h.plot()\n",
    "\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745caebc-eadd-4453-905a-1dbf65b4d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (Hist.new\n",
    "     .Reg(8, 0, 8, name='muon_count', label='Number of Muons')\n",
    "     .StrCat([], name='cut', label='Cut Type', growth=True)\n",
    "     .Int64()\n",
    "     )\n",
    "h.fill(muon_count=ak.count(r['lep_pt'], axis=-1), cut='All')\n",
    "h.fill(muon_count=ak.count(r_cut['pt'], axis=-1), cut='eta')\n",
    "artists = h.plot()\n",
    "\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c78322-e364-4a4c-a6ea-27e4d167c751",
   "metadata": {},
   "source": [
    "* We cut the number of leptons per event\n",
    "* We now have some events with zero leptons - but those events were still returned\n",
    "* We could remove them by doing a cut on the number of leptons..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7268fe-e6d7-420b-ad0c-1c6315664e85",
   "metadata": {},
   "source": [
    "## CMS Run 1 AOD Files\n",
    "\n",
    "Differences between FLAT ROOT files and CMS RUN 1 AOD Files:\n",
    "\n",
    "* You must use an (old) version of CMSSW, a big software framework, to read these files!!\n",
    "* Data in these files is stored event or row-wise: electrons, and then the $p_T$ and $\\eta$ of each electron.\n",
    "* Some datasets are ~7 TB!! It takes about 30 minutes to run on those when things are working well: we will be using a data from an earlier run that has automatically been locally cached.\n",
    "\n",
    "Start with a 60GB SM [Higgs dataset](http://opendata.cern.ch/record/1507) ($H \\rightarrow ZZ \\rightarrow \\ell \\ell \\ell \\ell$). In CERN OpenData's catalog, this is record 1507 (pulled straight from the URL: http://opendata.cern.ch/record/1507)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465d7c5-c195-427f-b23a-a6384a06dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hzz_4l_source = ServiceXSourceCMSRun1AOD('cernopendata://1507', backend='cms_run1_aod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcd0f5-eef7-45be-8266-6af393d5825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = (hzz_4l_source \\\n",
    "     .Select(lambda e: e.TrackMuons(\"globalMuons\"))\n",
    "     .Select(lambda muons: muons.Select(lambda m: m.pt()))\n",
    "     .AsAwkwardArray(['mu_pt']) \\\n",
    "     .value()\n",
    "    )\n",
    "r.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa832e4-34d8-4dff-bc60-976d8123d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cut = (hzz_4l_source \\\n",
    "         .Select(lambda e: e.TrackMuons(\"globalMuons\"))\n",
    "         .Select(lambda muons: muons.Where(lambda m: abs(m.eta()) < 1.0))\n",
    "         .Select(lambda muons: muons.Select(lambda m: m.pt()))\n",
    "         .AsAwkwardArray(['mu_pt']) \\\n",
    "         .value()\n",
    "    )\n",
    "r.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f18d6-db9a-4957-8fb8-67a78757f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (Hist.new\n",
    "     .Reg(8, 0, 8, name='muon_count', label='Number of Muons')\n",
    "     .StrCat([], name='cut', label='Cut Type', growth=True)\n",
    "     .Int64()\n",
    "     )\n",
    "h.fill(muon_count=ak.count(r['mu_pt'], axis=-1), cut='All')\n",
    "h.fill(muon_count=ak.count(r_cut['mu_pt'], axis=-1), cut='eta')\n",
    "artists = h.plot()\n",
    "\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc428a-80e3-4c21-b3e2-ea5b9ade906f",
   "metadata": {},
   "source": [
    "Again, a very similar behavior here!\n",
    "\n",
    "* Note that CMS muons are **all** muons, so a lot more quality cuts must be done to compare them with ATLAS's muons.\n",
    "* ATLAS's AOD files were skimmed down to make those datasets for the educational purposes: so a lot of the skimming is done early for those files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78663c25-e99b-4b10-a20e-26c68d8d031f",
   "metadata": {},
   "source": [
    "## Using Coffea\n",
    "\n",
    "`ServiceX`:\n",
    "\n",
    "* Gets columnar data from any format that can a translator has been written for (ATLAS Run 2 xAOD, CMS Run 1 AOD, uproot-able ROOT files, soon some dark matter experiments, etc.)\n",
    "* Slims, skims, generates calculated quantities\n",
    "\n",
    "Think _ntuplizer_.\n",
    "\n",
    "`coffea`:\n",
    "\n",
    "* Used `awkward` and friends to perform the final analysis\n",
    "* Plotting\n",
    "* Distributed running\n",
    "* Good at running on a large number of datasets at once\n",
    "\n",
    "`coffea` is arranged around processors that do the physics. Each processor runs once per file, and results are combined for a dataset.\n",
    "\n",
    "First define a dummy (representative) dataset and apply the operations on it we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31d058-e63a-4267-a698-7e8f4505fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ServiceXSourceUpROOT('cernopendata://dummy',  \"mimi\", backend='open_uproot')\n",
    "ds.return_qastle = True  # Magic\n",
    "\n",
    "selection_atlas = (ds\n",
    "                     .Select(lambda e: Zip({'lep_pt': e['lep_pt'], 'lep_eta': e['lep_eta']}))\n",
    "                     .Select(lambda leps: leps.Where(lambda l: abs(l.lep_eta) < 1.0))\n",
    "                     .Select(lambda leps: {'lep_pt': leps.lep_pt, 'lep_eta': leps.lep_eta})\n",
    "                     .AsParquetFiles('junk.parquet')\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c661d3-cc08-43ed-99cd-5e882d747f8b",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "* no call to `value`: We do not want to try to render this bogus expression.\n",
    "* We want to return parquet files - this is what `coffea` will be eating and sending to the processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a2e89-269a-457a-bd27-60d6f5ed689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.processor.servicex import DataSource, Analysis\n",
    "from coffea.processor.servicex import LocalExecutor\n",
    "from servicex import ServiceXDataset\n",
    "from coffea import processor\n",
    "\n",
    "class atlas_demo_processor(Analysis):\n",
    "    @staticmethod\n",
    "    def process(events):\n",
    "        import awkward as ak\n",
    "        from collections import defaultdict\n",
    "\n",
    "        sumw = defaultdict(float)\n",
    "        h = (Hist.new\n",
    "             .Reg(50, 0, 200, name='lep_pt', label='Lepton $p_T$ [GeV]')\n",
    "             .StrCat([], name='dataset', label='Dataset', growth=True)\n",
    "             .Int64()\n",
    "             )\n",
    "\n",
    "        dataset = events.metadata['dataset']\n",
    "        leptons = events.lep\n",
    "\n",
    "        h.fill(\n",
    "            dataset=dataset,\n",
    "            lep_pt = ak.flatten(leptons.pt/1000.0)\n",
    "        )\n",
    "                \n",
    "        return {\n",
    "            \"sumw\": sumw,\n",
    "            \"pt\": h\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbea86b-169b-4fd9-9e3a-22828bf1b311",
   "metadata": {},
   "source": [
    "Now we create a real dataset and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8fec2e-f9f2-4e06-87c9-178cdea693aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ServiceXDataset([ggH125_ZZ4lep], backend_type='open_uproot',\n",
    "                           image='sslhep/servicex_func_adl_uproot_transformer:pr_fix_awk_bug')]\n",
    "c_datasets = DataSource(query=selection_atlas, metadata={'dataset': 'ggH125_ZZ4lep'}, datasets=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1142d-85e2-484b-8c62-87df90842b4f",
   "metadata": {},
   "source": [
    "This code is boiler plate:\n",
    "\n",
    "* Declare a dataset and a transformer image (were accidentally running an old version of awkward)\n",
    "* Create a datasource\n",
    "* Note the metadata - a useful way to pass information into your processor on a per-dataset basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b619a-2c2a-4642-bc67-37b09dd642e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = atlas_demo_processor()\n",
    "executor = LocalExecutor(datatype='parquet')\n",
    "\n",
    "async def run_updates_stream(accumulator_stream):\n",
    "  count = 0\n",
    "  async for coffea_info in accumulator_stream:\n",
    "    count += 1\n",
    "  return coffea_info\n",
    "\n",
    "result = await run_updates_stream(executor.execute(analysis, c_datasets))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713467d5-83ab-4478-b868-059bfa046fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = result['pt'].plot()\n",
    "\n",
    "ax = artists[0].stairs.axes  # get the axis\n",
    "ax.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f19759-95f6-4ddf-b8ae-ef23be82c38f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
