{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3810jvsc74a57bd03b01dae37977440b636d22625a08ccea3d4a5dd7dac9ee1bcc018aa68724fe57",
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python"
  },
  "interpreter": {
   "hash": "3b01dae37977440b636d22625a08ccea3d4a5dd7dac9ee1bcc018aa68724fe57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Build a first version of the event selection for $H \\rightarrow 4 \\ell$\n",
    "\n",
    "This will test Coffea to see if we can figure out how to use it with our code.\n",
    "\n",
    "First are the includes from coffea. This is based on the [example written by Ben](https://github.com/CoffeaTeam/coffea/blob/master/binder/servicex/ATLAS/LocalExample.ipynb)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from servicex import ServiceXDataset\n",
    "from coffea.processor.servicex import DataSource, FuncAdlDataset, Analysis\n",
    "from coffea.processor.servicex import LocalExecutor \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from coffea import hist, processor\n",
    "from IPython.display import display, update_display, HTML"
   ]
  },
  {
   "source": [
    "And imports connected with running servicex."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_adl import ObjectStream\n",
    "from func_adl_servicex import ServiceXSourceUpROOT\n",
    "from hist import Hist\n",
    "import mplhep as mpl\n",
    "import awkward as ak\n",
    "\n",
    "from utils import files"
   ]
  },
  {
   "source": [
    "Methods copied to help us get all leptons from the source files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_event_cuts (source: ObjectStream) -> ObjectStream:\n",
    "    '''Event level cuts for the analysis. Keep from sending data that we aren't going to need at all in the end.\n",
    "    '''\n",
    "    return (source\n",
    "        .Where(lambda e: e.trigE or e.trigM))\n",
    "def good_leptons(source: ObjectStream) -> ObjectStream:\n",
    "    '''Select out all good leptons from each event. Return their pt, eta, phi, and E, and other\n",
    "    things needed downstream.\n",
    "\n",
    "    Because uproot doesn't tie toegher the objects, we can't do any cuts at this point.\n",
    "    '''\n",
    "    return source.Select(lambda e:\n",
    "        {\n",
    "            'lep_pt': e.lep_pt,\n",
    "            'lep_eta': e.lep_eta,\n",
    "            'lep_phi': e.lep_phi,\n",
    "            'lep_energy': e.lep_E,\n",
    "            'lep_charge': e.lep_charge,\n",
    "            'lep_ptcone30': e.lep_ptcone30,\n",
    "            'lep_etcone20': e.lep_etcone20,\n",
    "            'lep_typeid': e.lep_type,\n",
    "            'lep_trackd0pvunbiased': e.lep_trackd0pvunbiased,\n",
    "            'lep_tracksigd0pvunbiased': e.lep_tracksigd0pvunbiased,\n",
    "            'lep_z0': e.lep_z0,\n",
    "        }) \\\n",
    "        .AsParquetFiles('junk.parquet')"
   ]
  },
  {
   "source": [
    "Create the `func_adl` cuts to get the data. The dataset we use here doesn't matter, as long as it \"looks\" like all the datasets we are going to be processing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ServiceXSourceUpROOT('cernopendata://dummy',  files['ggH125_ZZ4lep']['treename'], backend='open_uproot')\n",
    "ds.return_qastle = True\n",
    "leptons = good_leptons(apply_event_cuts(ds))"
   ]
  },
  {
   "source": [
    "The analysis code that will apply the 4 lepton cuts and make the 4 lepton mass plot."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATLAS_Higgs_4L(Analysis):\n",
    "    @staticmethod\n",
    "    def process(events):\n",
    "        import awkward as ak\n",
    "        from collections import defaultdict\n",
    "\n",
    "        sumw = defaultdict(float)\n",
    "        # TODO: Add channel so we can see the different shapes\n",
    "        # But plot1d seems to fail here\n",
    "        mass_hist = hist.Hist(\n",
    "            \"Events\",\n",
    "            hist.Cat(\"dataset\", \"Dataset\"),\n",
    "            hist.Bin(\"mass\", \"$Z_{ee}$ [GeV]\", 120, 60, 180),\n",
    "        )\n",
    "\n",
    "        dataset = events.metadata['dataset']\n",
    "        leptons = events.lep\n",
    "\n",
    "        # Good electon selection\n",
    "        electrons_mask = ((leptons.typeid == 11)\n",
    "            & (leptons.pt > 7000.0)\n",
    "            & (abs(leptons.eta) <2.47)\n",
    "            & (leptons.etcone20 / leptons.pt < 0.3)\n",
    "            & (leptons.ptcone30 / leptons.pt < 0.3)\n",
    "            & (abs(leptons.trackd0pvunbiased) / leptons.tracksigd0pvunbiased < 5)\n",
    "            & (abs(leptons.z0*np.sin(leptons.theta)) < 0.5)\n",
    "        )\n",
    "\n",
    "        electrons_good = leptons[electrons_mask]\n",
    "\n",
    "        # Good muon selection\n",
    "        muon_mask = ((leptons.typeid == 11)\n",
    "            & (leptons.pt > 5000.0)\n",
    "            & (abs(leptons.eta) <2.5)\n",
    "            & (leptons.etcone20 / leptons.pt < 0.3)\n",
    "            & (leptons.ptcone30 / leptons.pt < 0.3)\n",
    "            & (abs(leptons.trackd0pvunbiased) / leptons.tracksigd0pvunbiased < 3)\n",
    "            & (abs(leptons.z0*np.sin(leptons.theta)) < 0.5)\n",
    "        )\n",
    "\n",
    "        muons_good = leptons[leptons.typeid == 13]\n",
    "\n",
    "        # In order to cut in sorted lepton pt, we have to rebuild a lepton array here\n",
    "        leptons_good = ak.concatenate((electrons_good, muons_good), axis=1)\n",
    "        leptons_good_index = ak.argsort(leptons_good.pt, ascending=False)\n",
    "        leptons_good_sorted = leptons_good[leptons_good_index]\n",
    "\n",
    "        # Event level cuts now that we know the good leptons\n",
    "        # - We need to look at 4 good lepton events only\n",
    "        # - We need same flavor, so check for even numbers of each flavor\n",
    "        # - all charges must be balenced\n",
    "        event_mask = (\n",
    "            (ak.num(leptons_good_sorted) == 4)\n",
    "            & ((ak.num(electrons_good) == 0) | (ak.num(electrons_good) == 2) | (ak.num(electrons_good) == 4))\n",
    "            & ((ak.num(muons_good) == 0) | (ak.num(muons_good) == 2) | (ak.num(muons_good) == 4))\n",
    "            & (ak.sum(electrons_good.charge, axis=1) == 0)\n",
    "            & (ak.sum(muons_good.charge, axis=1) == 0)\n",
    "        )\n",
    "\n",
    "        # Next, we need to cut on the pT for the leading, sub-leading, and sub-sub-leading lepton\n",
    "        leptons_good_preselection = leptons_good[event_mask]\n",
    "        event_good_lepton_mask = (\n",
    "            (leptons_good_preselection[:,0].pt > 25000.0)\n",
    "            & (leptons_good_preselection[:,1].pt > 15000.0)\n",
    "            & (leptons_good_preselection[:,2].pt > 10000.0)\n",
    "        )\n",
    "\n",
    "        # Now, we need to rebuild the good muon and electron lists with those selections\n",
    "        muons_analysis = muons_good[event_mask][event_good_lepton_mask]\n",
    "        electrons_analysis = electrons_good[event_mask][event_good_lepton_mask]\n",
    "\n",
    "        # Lets do eemumu events - as there are no permutations there.abs\n",
    "        # At this point if there are two muons, there must be two electrons\n",
    "        eemumu_mask = (ak.num(muons_analysis) == 2)\n",
    "        muon_eemumu = muons_analysis[eemumu_mask]\n",
    "        electrons_eemumu = electrons_analysis[eemumu_mask]\n",
    "        z1_eemumu = muon_eemumu[:,0] + muon_eemumu[:,1]\n",
    "        z2_eemumu = electrons_eemumu[:,0] + electrons_eemumu[:,1]\n",
    "        h_eemumu = z1_eemumu + z2_eemumu\n",
    "\n",
    "        sumw[dataset] += len(h_eemumu)\n",
    "        mass_hist.fill(\n",
    "            dataset=dataset,\n",
    "            mass=h_eemumu.mass/1000.0,\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"sumw\": sumw,\n",
    "            \"mass\": mass_hist,\n",
    "        }"
   ]
  },
  {
   "source": [
    "Create the data source that we will be running against."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(name: str, query: ObjectStream):\n",
    "    '''Create a ServiceX Datasource for a particular ATLAS Open data file\n",
    "    '''\n",
    "    datasets = [ServiceXDataset(files[name]['files'], backend_type='open_uproot')]\n",
    "    return DataSource(query=query, metadata={'dataset': name}, datasets=datasets)"
   ]
  },
  {
   "source": [
    "And run!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype([('x', '<f4'), ('y', '<f4'), ('z', '<f4'), ('t', '<f4')]), dtype('int32')) -> None",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-dfdd6b41f91c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Why do I need run_updates_stream, why not just await on execute (which fails with async gen can't).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Perhaps something from aiostream can help here?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mrun_updates_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-dfdd6b41f91c>\u001b[0m in \u001b[0;36mrun_updates_stream\u001b[1;34m(accumulator_stream)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m   \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcoffea_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccumulator_stream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoffea_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\processor\\servicex\\executor.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, analysis, datasource)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# There is an accumulate pattern in the aiostream lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32masync\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mfinished_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstreamer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32min\u001b[0m \u001b[0masync_accumulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\processor\\accumulator.py\u001b[0m in \u001b[0;36masync_accumulate\u001b[1;34m(result_stream)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masync_accumulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult_stream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miadd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gordo\\Code\\iris-hep\\pyhep-2021-SX-OpenDataDemo\\.venv\\lib\\site-packages\\aiostream\\stream\\advanced.py\u001b[0m in \u001b[0;36mbase_combine\u001b[1;34m(source, switch, ordered, task_limit)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m# Get result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;31m# End of stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gordo\\Code\\iris-hep\\pyhep-2021-SX-OpenDataDemo\\.venv\\lib\\site-packages\\aiostream\\stream\\create.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\processor\\servicex\\executor.py\u001b[0m in \u001b[0;36minline_wait\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minline_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;34m\"This could be inline, but python 3.6\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\processor\\servicex\\local_executor.py\u001b[0m in \u001b[0;36m_async_analysis\u001b[1;34m(self, events_url, tree_name, process_func, datatype)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_async_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         return run_coffea_processor(\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mevents_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevents_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mtree_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtree_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\processor\\servicex\\executor.py\u001b[0m in \u001b[0;36mrun_coffea_processor\u001b[1;34m(events_url, tree_name, proc, datatype, explicit_func_pickle)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-de12a0adc914>\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(events)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0msumw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_eemumu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         mass_hist.fill(\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mmass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh_eemumu\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\hist\\hist_tools.py\u001b[0m in \u001b[0;36mfill\u001b[1;34m(self, **values)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             dense_indices = tuple(\n\u001b[0m\u001b[0;32m   1092\u001b[0m                 \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDenseAxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\hist\\hist_tools.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             dense_indices = tuple(\n\u001b[1;32m-> 1092\u001b[1;33m                 \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDenseAxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m             )\n\u001b[0;32m   1094\u001b[0m             xy = numpy.atleast_1d(\n",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\hist\\hist_tools.py\u001b[0m in \u001b[0;36mindex\u001b[1;34m(self, identifier)\u001b[0m\n\u001b[0;32m    558\u001b[0m                 idx = numpy.clip(\n\u001b[0;32m    559\u001b[0m                     numpy.floor(\n\u001b[1;32m--> 560\u001b[1;33m                         \u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                         \u001b[1;33m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                         \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype([('x', '<f4'), ('y', '<f4'), ('z', '<f4'), ('t', '<f4')]), dtype('int32')) -> None"
     ]
    }
   ],
   "source": [
    "analysis = ATLAS_Higgs_4L()\n",
    "# TODO: It would be good if datatype was determined automagically (there is enough info)\n",
    "executor = LocalExecutor(datatype='parquet')\n",
    "datasource = make_ds('ggH125_ZZ4lep', leptons)\n",
    "\n",
    "async def run_updates_stream(accumulator_stream):\n",
    "  global first\n",
    "\n",
    "  count = 0\n",
    "  async for coffea_info in accumulator_stream:\n",
    "    count += 1\n",
    "    print(count, coffea_info)\n",
    "  return coffea_info\n",
    "\n",
    "# Why do I need run_updates_stream, why not just await on execute (which fails with async gen can't).\n",
    "# Perhaps something from aiostream can help here?\n",
    "result = await run_updates_stream(executor.execute(analysis, datasource))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "plot1d() can only support up to two dimensions (one for axis, one to stack or overlay)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-86bbc3bbabec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\gordo\\code\\iris-hep\\coffea\\coffea\\hist\\plot.py\u001b[0m in \u001b[0;36mplot1d\u001b[1;34m(hist, ax, clear, overlay, stack, overflow, line_opts, fill_opts, error_opts, legend_opts, overlay_overflow, density, binwnorm, order)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    202\u001b[0m             \u001b[1;34m\"plot1d() can only support up to two dimensions (one for axis, one to stack or overlay)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: plot1d() can only support up to two dimensions (one for axis, one to stack or overlay)"
     ]
    }
   ],
   "source": [
    "hist.plot1d(result['mass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}