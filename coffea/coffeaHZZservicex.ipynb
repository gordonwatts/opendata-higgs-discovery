{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# For this notebook to work, you need to set up your environment as specified in the readme of https://github.com/gordonwatts/pyhep-2021-SX-OpenDataDemo\n",
    "\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from coffea.processor.servicex import Analysis, DataSource, LocalExecutor\n",
    "from func_adl import ObjectStream\n",
    "from func_adl_servicex import ServiceXSourceUpROOT\n",
    "from servicex.servicex import ServiceXDataset\n",
    "import hist\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import infofile # Same infofile used in https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "prefix = 'root://eospublic.cern.ch//eos/opendata/atlas/OutreachDatasets/2020-01-22/4lep/'\n",
    "\n",
    "fileset = {'Data': [prefix + 'Data/data_A.4lep.root',\n",
    "                    prefix + 'Data/data_B.4lep.root',\n",
    "                    prefix + 'Data/data_C.4lep.root',\n",
    "                    prefix + 'Data/data_D.4lep.root'],\n",
    "           'Background $Z,tt^{bar}$': [prefix + 'MC/mc_361106.Zee.4lep.root',\n",
    "                                       prefix + 'MC/mc_361107.Zmumu.4lep.root',\n",
    "                                       prefix + 'MC/mc_410000.ttbar_lep.4lep.root'],\n",
    "           'Background $ZZ^{star}$': [prefix + 'MC/mc_363490.llll.4lep.root'],\n",
    "           'Signal ($m_H$ = 125 GeV)': [prefix + 'MC/mc_345060.ggH125_ZZ4lep.4lep.root',\n",
    "                                        prefix + 'MC/mc_344235.VBFH125_ZZ4lep.4lep.root',\n",
    "                                        prefix + 'MC/mc_341964.WH125_ZZ4lep.4lep.root',\n",
    "                                        prefix + 'MC/mc_341947.ZH125_ZZ4lep.4lep.root']}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Method from https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata\n",
    "\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] # open infofile\n",
    "    xsec_weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    return xsec_weight # return cross-section weight"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Adapted from method from https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata\n",
    "\n",
    "def calc_mllll(lep_pt,lep_eta,lep_phi,lep_E):\n",
    "    # first lepton is [0], 2nd lepton is [1] etc\n",
    "    px_0 = lep_pt[:,0]*np.cos(lep_phi[:,0]) # x-component of lep[0] momentum\n",
    "    py_0 = lep_pt[:,0]*np.sin(lep_phi[:,0]) # y-component of lep[0] momentum\n",
    "    pz_0 = lep_pt[:,0]*np.sinh(lep_eta[:,0]) # z-component of lep[0] momentum\n",
    "    px_1 = lep_pt[:,1]*np.cos(lep_phi[:,1]) # x-component of lep[1] momentum\n",
    "    py_1 = lep_pt[:,1]*np.sin(lep_phi[:,1]) # y-component of lep[1] momentum\n",
    "    pz_1 = lep_pt[:,1]*np.sinh(lep_eta[:,1]) # z-component of lep[1] momentum\n",
    "    px_2 = lep_pt[:,2]*np.cos(lep_phi[:,2]) # x-component of lep[2] momentum\n",
    "    py_2 = lep_pt[:,2]*np.sin(lep_phi[:,2]) # y-component of lep[2] momentum\n",
    "    pz_2 = lep_pt[:,2]*np.sinh(lep_eta[:,2]) # z-component of lep[3] momentum\n",
    "    px_3 = lep_pt[:,3]*np.cos(lep_phi[:,3]) # x-component of lep[3] momentum\n",
    "    py_3 = lep_pt[:,3]*np.sin(lep_phi[:,3]) # y-component of lep[3] momentum\n",
    "    pz_3 = lep_pt[:,3]*np.sinh(lep_eta[:,3]) # z-component of lep[3] momentum\n",
    "    sumpx = px_0 + px_1 + px_2 + px_3 # x-component of 4-lepton momentum\n",
    "    sumpy = py_0 + py_1 + py_2 + py_3 # y-component of 4-lepton momentum\n",
    "    sumpz = pz_0 + pz_1 + pz_2 + pz_3 # z-component of 4-lepton momentum\n",
    "    sumE = lep_E[:,0] + lep_E[:,1] + lep_E[:,2] + lep_E[:,3] # energy of 4-lepton system\n",
    "    return np.sqrt(sumE**2 - sumpx**2 - sumpy**2 - sumpz**2)/1000 #/1000 to go from MeV to GeV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Adapted from methods from https://github.com/atlas-outreach-data-tools/notebooks-collection-opendata\n",
    "\n",
    "# cut on lepton charge\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_charge(lep_charge):\n",
    "# throw away when sum of lepton charges is not equal to 0\n",
    "# first lepton is [0], 2nd lepton is [1] etc\n",
    "    return ((lep_charge[:,0] + lep_charge[:,1] + lep_charge[:,2] + lep_charge[:,3]) != 0)\n",
    "\n",
    "# cut on lepton type\n",
    "# paper: \"selecting two pairs of isolated leptons, each of which is comprised of two leptons with the same flavour and opposite charge\"\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "# throw away when none of eeee, mumumumu, eemumu\n",
    "    sum_lep_type = lep_type[:,0] + lep_type[:,1] + lep_type[:,2] + lep_type[:,3]\n",
    "    return ((sum_lep_type != 44) & (sum_lep_type != 48) & (sum_lep_type != 52))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class HZZAnalysis(Analysis):\n",
    "    def process(self, events):\n",
    "        # Get dataset name and lepton information from events\n",
    "        dataset = events.metadata['dataset']\n",
    "        leptons = events.lep\n",
    "        \n",
    "        # Cut events based on lepton charge, then update leptons\n",
    "        events = events[~cut_lep_charge(leptons.charge)]\n",
    "        leptons = events.lep\n",
    "        \n",
    "        # Cut events based on lepton type, then update leptons\n",
    "        events = events[~cut_lep_type(leptons.typeid)]\n",
    "        leptons = events.lep\n",
    "        \n",
    "        # Calculate the mllll for each event\n",
    "        mllll = calc_mllll(leptons.pt, leptons.eta, leptons.phi, leptons.energy)\n",
    "        \n",
    "        if (dataset == 'Data'):\n",
    "            # Create and fill a histogram for mllll\n",
    "            mllllhist = (\n",
    "                hist.Hist.new\n",
    "                .Reg(34, 80, 250, name='mllll', label='4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]')\n",
    "                .StrCat(['Data'], name='dataset', label='Dataset')\n",
    "                .Weight()\n",
    "                .fill(mllll=mllll, dataset=dataset)\n",
    "            )\n",
    "        else:\n",
    "            # Extract the sample name from the filename metadata with regex\n",
    "            sample = re.findall(r'mc_\\d+\\.(.+)\\.4lep', events.metadata['filename'])[0]\n",
    "            \n",
    "            # Calculate the event weights\n",
    "            totalWeights = get_xsec_weight(sample) * events.mcWeight * events.scaleFactor\n",
    "            \n",
    "            # Create and fill a weighted histogram for mllll\n",
    "            mllllhist = (\n",
    "                hist.Hist.new\n",
    "                .Reg(34, 80, 250, name='mllll', label='4-lepton invariant mass $\\mathrm{m_{4l}}$ [GeV]')\n",
    "                .StrCat(['Background $Z,tt^{bar}$', 'Background $ZZ^{star}$', 'Signal ($m_H$ = 125 GeV)'], name='dataset', label='Dataset')\n",
    "                .Weight()\n",
    "                .fill(mllll=mllll, dataset=dataset, weight=totalWeights)\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            'entries': len(events),\n",
    "            'mllll': mllllhist\n",
    "        }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Adapted from methods from https://github.com/gordonwatts/pyhep-2021-SX-OpenDataDemo\n",
    "\n",
    "def good_leptons(source: ObjectStream) -> ObjectStream:\n",
    "    '''Select out all good leptons from each event. Return their pt, eta, phi, and E, and other\n",
    "    things needed downstream.\n",
    "\n",
    "    Because uproot doesn't tie together the objects, we can't do any cuts at this point.\n",
    "    '''\n",
    "    return source.Select(lambda e:\n",
    "        {\n",
    "            'lep_pt': e.lep_pt,\n",
    "            'lep_eta': e.lep_eta,\n",
    "            'lep_phi': e.lep_phi,\n",
    "            'lep_energy': e.lep_E,\n",
    "            'lep_charge': e.lep_charge,\n",
    "            'lep_typeid': e.lep_type,\n",
    "            'mcWeight': e.mcWeight,\n",
    "            'scaleFactor': e.scaleFactor_ELE*e.scaleFactor_MUON*e.scaleFactor_LepTRIGGER*e.scaleFactor_PILEUP,\n",
    "        }) \n",
    "\n",
    "def make_ds(name: str, query: ObjectStream):\n",
    "    '''Create a ServiceX Datasource for a particular ATLAS Open data file\n",
    "    '''\n",
    "    # datasets = [ServiceXDataset(fileset[name], backend_name='uproot-af', image='sslhep/servicex_func_adl_uproot_transformer:pr_fix_awk_bug')]\n",
    "    datasets = [ServiceXDataset(fileset[name], backend_name='uproot-af')]\n",
    "    return DataSource(query=query, metadata={'dataset': name}, datasets=datasets)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Adapted from method from https://github.com/gordonwatts/pyhep-2021-SX-OpenDataDemo\n",
    "\n",
    "async def run_analysis():\n",
    "    '''Run on a known analysis file/files and return the result.\n",
    "    Should be fine to start many of these at once.\n",
    "    '''\n",
    "    # Parse the dataset\n",
    "    ds_names = list(fileset.keys())\n",
    "\n",
    "    # Create the query\n",
    "    ds = ServiceXSourceUpROOT('cernopendata://dummy',  'mini', 'uproot-af')\n",
    "    ds.return_qastle = True\n",
    "    leptons = good_leptons(ds)\n",
    "\n",
    "    # Get data source for this run\n",
    "    executor = LocalExecutor()\n",
    "    datasources = [make_ds(ds_name, leptons) for ds_name in ds_names]\n",
    "\n",
    "    # Create the analysis and we can run from there\n",
    "    analysis = HZZAnalysis()\n",
    "\n",
    "    async def run_updates_stream(accumulator_stream, name):\n",
    "        '''Run to get the last item in the stream'''\n",
    "        coffea_info = None\n",
    "        try:\n",
    "            async for coffea_info in accumulator_stream:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failure while processing {name}') from e\n",
    "        return coffea_info\n",
    "\n",
    "    all_plots = await asyncio.gather(*[run_updates_stream(executor.execute(analysis, source), source.metadata['dataset']) for source in datasources])\n",
    "\n",
    "    # Combine the MC plots\n",
    "    all_MC_plots = [p['mllll'] for p in all_plots[1:]]\n",
    "    MC_plot = all_MC_plots[0]\n",
    "    for p in all_MC_plots[1:]:\n",
    "        MC_plot += p\n",
    "\n",
    "    return {\n",
    "        'Data': all_plots[0]['mllll'],\n",
    "        'MC': MC_plot\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "output = await run_analysis()\n",
    "finish_time = time.time()\n",
    "\n",
    "print(\"Total runtime in seconds: \" + str(finish_time - start_time))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ilija\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\numba\\core\\cpu.py:97: UserWarning: Numba extension module 'awkward1._connect._numba' failed to load due to 'ImportError(generic_type: type \"kernel_lib\" is already registered!)'.\n",
      "  numba.core.entrypoints.init_all()\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aed668fb1d9649b1856614ed0d4aa03e"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='[root://eospublic.ce...', layout=Layout(flex='2'), max=90…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ff9009cce064050b7404cb74943e814"
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='        [root://eospublic.ce... Downloaded', layout=Layou…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ilija\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\traitlets\\traitlets.py:1189: RuntimeWarning: coroutine 'LocalExecutor._async_analysis' was never awaited\n",
      "  for name in list(cache.keys()):\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "Exception",
     "evalue": "Failure while processing Data",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-54d0b21d26d8>\u001b[0m in \u001b[0;36mrun_updates_stream\u001b[1;34m(accumulator_stream, name)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcoffea_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccumulator_stream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\coffea\\processor\\servicex\\executor.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, analysis, datasource, title)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32masync\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mfinished_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstreamer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32min\u001b[0m \u001b[0masync_accumulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\coffea\\processor\\accumulator.py\u001b[0m in \u001b[0;36masync_accumulate\u001b[1;34m(result_stream)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32masync\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult_stream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\aiostream\\stream\\advanced.py\u001b[0m in \u001b[0;36mbase_combine\u001b[1;34m(source, switch, ordered, task_limit)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\aiostream\\stream\\create.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\coffea\\processor\\servicex\\executor.py\u001b[0m in \u001b[0;36minline_wait\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;34m\"This could be inline, but python 3.6\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\coffea\\processor\\servicex\\local_executor.py\u001b[0m in \u001b[0;36m_async_analysis\u001b[1;34m(self, events_url, tree_name, data_type, meta_data, process_func)\u001b[0m\n\u001b[0;32m     58\u001b[0m     ):\n\u001b[1;32m---> 59\u001b[1;33m         return run_coffea_processor(\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mevents_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevents_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\coffea\\processor\\servicex\\executor.py\u001b[0m in \u001b[0;36mrun_coffea_processor\u001b[1;34m(events_url, tree_name, proc, data_type, meta_data)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-21100db8f447>\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, events)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# Extract the sample name from the filename metadata with regex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'mc_\\d+\\.(.+)\\.4lep'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-046e919443cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mrun_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfinish_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-54d0b21d26d8>\u001b[0m in \u001b[0;36mrun_analysis\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcoffea_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mall_plots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun_updates_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dataset'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msource\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasources\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Combine the MC plots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-54d0b21d26d8>\u001b[0m in \u001b[0;36mrun_updates_stream\u001b[1;34m(accumulator_stream, name)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Failure while processing {name}'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcoffea_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Failure while processing Data"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the histograms\n",
    "hist.Hist.plot1d(output['Data'], histtype='errorbar', color='black')\n",
    "hist.Hist.plot1d(output['MC'], stack=True, histtype='fill', color=['purple', 'red', 'cyan'])\n",
    "\n",
    "# Basic bin parameters\n",
    "xmin = 80\n",
    "xmax = 250\n",
    "step_size = 5\n",
    "\n",
    "bin_centers = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                        stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                        step=step_size ) # Spacing between values\n",
    "\n",
    "# Calculate background statistical uncertainty\n",
    "# Remove the \"[:,:2]\" expressions to use all MC datasets with background and signal combined\n",
    "mc_tot_var = np.sum(output['MC'].variances()[:,:2], axis=1)\n",
    "mc_err = np.sqrt(mc_tot_var)\n",
    "mc_tot_height = np.sum(output['MC'].values()[:,:2], axis=1)\n",
    "\n",
    "# Plot background statistical uncertainty\n",
    "plt.bar(bin_centers, # x\n",
    "        2*mc_err, # heights\n",
    "        alpha=0.5, # half transparency\n",
    "        bottom=mc_tot_height-mc_err, color='none', \n",
    "        hatch=\"////\", width=step_size, label='Stat. Unc.')\n",
    "\n",
    "# Tune plot appearance\n",
    "main_axes = plt.gca()\n",
    "main_axes.set_xlim(left=xmin, right=xmax)\n",
    "main_axes.set_ylim(bottom=0, top=np.amax(output['Data'].values())*1.6)\n",
    "main_axes.set_ylabel('Events / '+str(step_size)+' GeV')\n",
    "main_axes.legend(frameon=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "f2575392019334285e0602a4035eec46b9260ee4c95297ea34ade6e3c8b8fcaf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}